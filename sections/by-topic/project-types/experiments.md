# Experiments Repositories

## Example Large Language Model Python Gui Build [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Example-LLM-Python-GUI-Build)
No description provided

## Fun Large Language Model Data Prompts [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Fun-LLM-Data-Prompts)
As prompting fro data analysis & vis is quite specific, a small side collection of prompts for this purpose

## Large Language Model Evaluation Prompts [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/LLM-Evaluation-Prompts)
A few prompts that I am storing in a repo for the purpose of running controlled experiments comparing and benchmarking different LLMs for defined use-cases

## Large Language Model Experiment Notebook [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/LLM-Experiment-Notebook)
Experiments in evaluating various prompting strategies and LLM performance generally

## Large Language Model Output Notes [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/LLM-Output-Notes)
First entry documentation repository for notes mostly unedited from LLMs

## Large Language Model Outputs [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/LLM-Outputs)
Interesting GPT outputs demonstrating specific capabilities

## Llms On Llms [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/LLMs-on-LLMs)
Large language models (LLMs) explaining themselves - and how to make best use of them (prompt engineering). Often insightful, though accuracy not guaranteed!

## Prompt Puncutation Experiment [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Prompt-Puncutation-Experiment)
Experimenting to test the effect of puncutation in prompts on inference quality

## Two Ais Talk [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Two-AIs-Talk)
Experiment:  two AI agents, each one thinks the other is a liar...


## AI Agent UN [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/AI-Agent-UN)
Experimentary implementation of a model real life political body populated by representative AI agents

## Long AI Prompting Experiment [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Long-AI-Prompting-Experiment)
Experiment testing the "added value" of long context-dense prompts (versus casual converastional prompts) and the value of a voice "prompt optimisation" agent

## Experiments And Evaluations Index [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Experiments-And-Evaluations-Index)
Index of repositories concerning AI evaluations and experiments

## Ai Podcast Experiment 1125 [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/AI-Podcast-Experiment-1125)

