# Prompt-libraries Repositories

## Awesome Chatgpt Prompts [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/awesome-chatgpt-prompts)
This repo includes ChatGPT prompt curation to use ChatGPT better.

## Environmental Data   Artificial Intelligence Assistants [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Environmental-Data---AI-Assistants)
This repository is a gathering of AI assistants that I've developed for analysing sustainability-related data

## Fun Large Language Model Data Prompts [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Fun-LLM-Data-Prompts)
As prompting fro data analysis & vis is quite specific, a small side collection of prompts for this purpose

## Generative Pre-trained Transformer Repo Utility [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/GPT-Repo-Utility)
Utility for saving GPT outputs into an organised markdown repository

## Large Language Model Evaluation Prompts [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/LLM-Evaluation-Prompts)
A few prompts that I am storing in a repo for the purpose of running controlled experiments comparing and benchmarking different LLMs for defined use-cases

## My Principles Of Prompting [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/My-Principles-Of-Prompting)
A small and opinionated repository of my thoughts about prompting LLMs to maximise their utility for specific use-cases

## Openwebui Prompt Library [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/OpenWebUI-Prompt-Library)
A selection of prompts designed for use with Open Web UI (rather than conventional prompts, they're more useful for steering existing conversations)

## Output Hub [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Output-Hub)
An admin application I'm developing for managing all aspects of working with LLMs professionally and at scale, with functions for prompt logging, prompt library, and custom LLM agent inventorising. Aspiration: add code to notes gradually as project matures!

## Prompt And Output Separator [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Prompt-And-Output-Separator)
Streamlit-deployed app which attempts to separate prompts and outputs from continuous text files

## Prompt Builder [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Prompt-Builder)
Work in progress. Assemble prompts based upon templated forms in the browser. 

## Prompt Engineering Resources [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Prompt-Engineering-Resources)
Lists of resources and tools for prompt engineering and evaluation

## Prompt Library [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Prompt-Library)
A repository of prompts I've used when working with LLMs as well as some example outputs and notes

## Prompt Puncutation Experiment [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Prompt-Puncutation-Experiment)
Experimenting to test the effect of puncutation in prompts on inference quality

## Prompts And Outputs [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/Prompts-And-Outputs)
A vault of over 2,000 prompts and outputs derived from interactions with various large language models (LLMs)

## Roocode Mode Prompts [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/RooCode-Mode-Prompts)
Some custom mode-setting system prompts for Roo Code

## System Prompt Factory [![View Repo](https://img.shields.io/badge/view-repo-green)](https://github.com/danielrosehill/System-Prompt-Factory)
A system prompt generation UI that combines model and user characteristics to generate more targeted (but still general) system prompts for LLMs

